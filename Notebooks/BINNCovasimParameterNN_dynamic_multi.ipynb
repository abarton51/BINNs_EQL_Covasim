{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Teddy\\anaconda3\\envs\\reu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from Modules.Utils.Imports import *\n",
    "from Modules.Models.BuildBINNs import BINNCovasim\n",
    "from Modules.Utils.ModelWrapper import ModelWrapper\n",
    "\n",
    "import Modules.Utils.PDESolver as PDESolver\n",
    "import Modules.Loaders.DataFormatter as DF\n",
    "from utils import get_case_name, lasso_parameter_fitting\n",
    "import seaborn as sns\n",
    "# sns.set(font_scale=1.2, style='white')\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def to_torch(x):\n",
    "    return torch.from_numpy(x).float().to(device)\n",
    "def to_numpy(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(GetLowestGPU(pick_from=[0,1,2,3]))\n",
    "# instantiate BINN\n",
    "path = '../Data/covasim_data/'\n",
    "population = 200000\n",
    "test_prob = 0.1\n",
    "trace_prob = 0.3\n",
    "keep_d = True\n",
    "retrain = False\n",
    "dynamic = True\n",
    "chi_type = 'piecewise'\n",
    "case_name = get_case_name(population, test_prob, trace_prob, keep_d, dynamic=dynamic, chi_type=chi_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../models/covasim/2023-06-21_00-12-29\\200000_0.1_0.3_dynamic_piecewise\\0\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../models/covasim/2023-06-21_00-12-29\\\\200000_0.1_0.3_dynamic_piecewise\\\\0_best_val_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(model\u001b[39m.\u001b[39msave_name)\n\u001b[0;32m     19\u001b[0m model\u001b[39m.\u001b[39msave_name \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_best_val\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 20\u001b[0m model\u001b[39m.\u001b[39;49mload(model\u001b[39m.\u001b[39;49msave_name \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m_model\u001b[39;49m\u001b[39m'\u001b[39;49m, device\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m     21\u001b[0m save_path \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39msave_folder\n\u001b[0;32m     22\u001b[0m \u001b[39m# grab initial condition\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\Documents\\UG Research\\DRUMS\\COVASIM_EQL_BINNS\\Notebooks\\..\\Modules\\Utils\\ModelWrapper.py:536\u001b[0m, in \u001b[0;36mModelWrapper.load\u001b[1;34m(self, model_weights, opt_weights, reg_weights, device)\u001b[0m\n\u001b[0;32m    531\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[0;32m    532\u001b[0m \u001b[39mLoads model weights and optionally optimizer weights.\u001b[39;00m\n\u001b[0;32m    533\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39m# load model weights\u001b[39;00m\n\u001b[1;32m--> 536\u001b[0m weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mload(model_weights, map_location\u001b[39m=\u001b[39;49mdevice)\n\u001b[0;32m    537\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mload_state_dict(weights)\n\u001b[0;32m    538\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\anaconda3\\envs\\reu_env\\lib\\site-packages\\torch\\serialization.py:699\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m pickle_load_args\u001b[39m.\u001b[39mkeys():\n\u001b[0;32m    697\u001b[0m     pickle_load_args[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m--> 699\u001b[0m \u001b[39mwith\u001b[39;00m _open_file_like(f, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m opened_file:\n\u001b[0;32m    700\u001b[0m     \u001b[39mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[0;32m    701\u001b[0m         \u001b[39m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[0;32m    702\u001b[0m         \u001b[39m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[0;32m    703\u001b[0m         \u001b[39m# reset back to the original position.\u001b[39;00m\n\u001b[0;32m    704\u001b[0m         orig_position \u001b[39m=\u001b[39m opened_file\u001b[39m.\u001b[39mtell()\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\anaconda3\\envs\\reu_env\\lib\\site-packages\\torch\\serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[0;32m    231\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    232\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m mode:\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\anaconda3\\envs\\reu_env\\lib\\site-packages\\torch\\serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, mode):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39msuper\u001b[39m(_open_file, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mopen\u001b[39;49m(name, mode))\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../models/covasim/2023-06-21_00-12-29\\\\200000_0.1_0.3_dynamic_piecewise\\\\0_best_val_model'"
     ]
    }
   ],
   "source": [
    "n_runs = 100\n",
    "n_samples = 50\n",
    "params = DF.load_covasim_data(path, population, test_prob, trace_prob, keep_d, case_name + '_' + str(n_runs), plot=False)\n",
    "for i in range(n_samples): # loop through each sample\n",
    "    data = params['data'][i]\n",
    "    data = (data / params['population']).to_numpy()\n",
    "    N = len(data)\n",
    "    t_max = N - 1\n",
    "    t = np.arange(N)\n",
    "    # params.pop('data')\n",
    "    tracing_array = params['tracing_array']\n",
    "    mydir = '../models/covasim/2023-06-21_00-12-29'  # piecewise\n",
    "    binn = BINNCovasim(params, t_max, tracing_array, keep_d=keep_d).to(device)\n",
    "    parameters = binn.parameters()\n",
    "    model = ModelWrapper(binn, None, None, save_name=os.path.join(mydir, case_name, str(i)))\n",
    "\n",
    "    # load model weights\n",
    "    model.save_name += '_best_val'\n",
    "    model.load(model.save_name + '_model', device=device)\n",
    "    save_path = model.save_folder\n",
    "    # grab initial condition\n",
    "    u0 = data[0, :].copy()\n",
    "\n",
    "    # grab value ranges\n",
    "    yita_lb, yita_ub = model.model.yita_lb, model.model.yita_ub\n",
    "    beta_lb, beta_ub = model.model.beta_lb, model.model.beta_ub\n",
    "    tau_lb, tau_ub = model.model.tau_lb, model.model.tau_ub\n",
    "\n",
    "    # learned contact_rate function\n",
    "    def contact_rate(u):\n",
    "        res = binn.eta_func(to_torch(u)) # [:,[0,3,4]]\n",
    "        return to_numpy(res)\n",
    "\n",
    "    def beta(u):\n",
    "        res = binn.beta_func(to_torch(u))\n",
    "        return to_numpy(res)\n",
    "\n",
    "    def tau(u):\n",
    "        res = binn.tau_func(to_torch(u))\n",
    "        return to_numpy(res)\n",
    "\n",
    "    #%% visualization for eta\n",
    "    s_min, s_max = data[:,0].min(), data[:,0].max()\n",
    "    # a_min, a_max = 0.0, 0.015 # data[:,3].min(), data[:,3].max()\n",
    "    # y_min, y_max = 0.0, 0.015 # data[:,4].min(), data[:,4].max()\n",
    "    a_min, a_max = data[:,3].min(), data[:,3].max()\n",
    "    y_min, y_max = data[:,4].min(), data[:,4].max()\n",
    "    # chi_min, chi_max = 0.0, params['eff_ub']\n",
    "\n",
    "    a_grid = np.linspace(s_min, s_max, 10)\n",
    "    b_grid = np.linspace(a_min, a_max, 10)\n",
    "    c_grid = np.linspace(y_min, y_max, 10)\n",
    "    labels = ['S', 'A', 'Y']\n",
    "    # for 3 inputs\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    for i in range(3):\n",
    "        if i == 0:\n",
    "            X, Y = np.meshgrid(a_grid, b_grid)\n",
    "            Z = np.ones_like(X) * c_grid.mean()\n",
    "            x_label, y_label = labels[0], labels[1]\n",
    "        elif i == 1:\n",
    "            X, Z = np.meshgrid(a_grid, c_grid)\n",
    "            Y = np.ones_like(X) * b_grid.mean()\n",
    "            x_label, y_label = labels[0], labels[2]\n",
    "        else:\n",
    "            Y, Z = np.meshgrid(b_grid, c_grid)\n",
    "            X = np.ones_like(Y) * a_grid.mean()\n",
    "            x_label, y_label = labels[1], labels[2]\n",
    "        u_grid = np.stack([np.ravel(X), np.ravel(Y), np.ravel(Z)], axis=1)\n",
    "        res = contact_rate(u_grid)\n",
    "        res = yita_lb + (yita_ub - yita_lb) * res  # scaling\n",
    "        res = res[:,0].reshape(X.shape)\n",
    "        res = np.round(res, decimals=6)\n",
    "        ax = fig.add_subplot(1, 3, i + 1, projection='3d')\n",
    "        if i == 0:\n",
    "            ax.plot_surface(X, Y, res, cmap=cm.coolwarm, alpha=1)\n",
    "            ax.scatter(X.reshape(-1), Y.reshape(-1), res.reshape(-1), s=5, c='k')\n",
    "        elif i == 1:\n",
    "            ax.plot_surface(X, Z, res, cmap=cm.coolwarm, alpha=1)\n",
    "            ax.scatter(X.reshape(-1), Z.reshape(-1), res.reshape(-1), s=5, c='k')\n",
    "        else:\n",
    "            ax.plot_surface(Y, Z, res, cmap=cm.coolwarm, alpha=1)\n",
    "            ax.scatter(Y.reshape(-1), Z.reshape(-1), res.reshape(-1), s=5, c='k')\n",
    "            plt.setp(ax.get_xticklabels(), rotation=15) # , ha=\"right\", rotation_mode=\"anchor\"\n",
    "        ax.set_xlabel(x_label)\n",
    "        ax.set_ylabel(y_label)\n",
    "        fig.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "\n",
    "    plt.tight_layout(pad=2)\n",
    "    plt.savefig(os.path.join(save_path, case_name + '_parameter_NN_eta' + '.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "    #%% visualization for beta\n",
    "    chi_min, chi_max = 0.05, params['eff_ub']\n",
    "\n",
    "    a_grid = np.linspace(0.5, 1.0, 10) # D + R + F\n",
    "    b_grid = np.linspace(chi_min, chi_max, 10)\n",
    "    labels = ['S + A + Y', r'$h(t)$']\n",
    "\n",
    "    X, Y = np.meshgrid(a_grid, b_grid)\n",
    "    x_label, y_label = labels[0], labels[1]\n",
    "    u_grid = np.stack([np.ravel(X), np.ravel(Y)], axis=1)\n",
    "    res = beta(u_grid) * params['n_contacts'] # * u_grid[:, [1]] *\n",
    "    res = res[:,0].reshape(X.shape)\n",
    "    res = np.round(res, decimals=6)\n",
    "    # res = beta_lb + (beta_ub - beta_lb) * res\n",
    "\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    ax.plot_surface(X, Y, res, cmap=cm.coolwarm, alpha=1)\n",
    "    ax.scatter(X.reshape(-1), Y.reshape(-1), res.reshape(-1), s=5, c='k')\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    # ax.set_zticks(np.arange(0,10.1, 2), np.arange(0,10.1, 2))\n",
    "    # ax.set_title(r'$\\beta(t)$')\n",
    "    plt.tight_layout(pad=2)\n",
    "    plt.savefig(os.path.join(save_path, case_name + '_parameter_NN_beta' + '.png'), dpi=300, bbox_inches='tight' )\n",
    "    plt.close()\n",
    "\n",
    "    #%% visualization for tau\n",
    "\n",
    "    a_grid = np.linspace(a_min, a_max, 10)\n",
    "    b_grid = np.linspace(y_min, y_max, 10)\n",
    "    labels = ['A', 'Y']\n",
    "\n",
    "    X, Y = np.meshgrid(a_grid, b_grid)\n",
    "    x_label, y_label = labels[0], labels[1]\n",
    "    u_grid = np.stack([np.ravel(X), np.ravel(Y)], axis=1)\n",
    "    res = tau(u_grid)\n",
    "    res = res[:,0].reshape(X.shape)\n",
    "    res = tau_lb + (tau_ub - tau_lb) * res # scaling\n",
    "    res = np.round(res, decimals=4)\n",
    "\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection='3d')\n",
    "    ax.plot_surface(X, Y, res, cmap=cm.coolwarm, alpha=1)\n",
    "    ax.scatter(X.reshape(-1), Y.reshape(-1), res.reshape(-1), s=5, c='k')\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    plt.tight_layout(pad=2)\n",
    "    plt.savefig(os.path.join(save_path, case_name + '_parameter_NN_tau' + '.png'), dpi=300, bbox_inches='tight') #\n",
    "    plt.close()\n",
    "\n",
    "    def get_samples_ct(u):\n",
    "        s, a, y =  u[:, 0][:, None], u[:, 1][:, None], u[:, 2][:, None]\n",
    "        candidates = [s, s**2, a, y] # s related terms\n",
    "        # candidates += [a]\n",
    "        # candidates += [y]\n",
    "        # candidates += [chi]\n",
    "        candidates = np.concatenate(candidates, axis=1)\n",
    "        return candidates\n",
    "\n",
    "    def get_samples_beta(u):\n",
    "        drf, chi = u[:, 0][:, None], u[:, 1][:, None]\n",
    "        candidates = [drf, chi] # , chi**2\n",
    "        candidates = np.concatenate(candidates, axis=1)\n",
    "        return candidates\n",
    "\n",
    "    def get_samples_tau(u):\n",
    "        a, y = u[:, 0][:, None], u[:, 1][:, None]\n",
    "        candidates = [a, y]\n",
    "        candidates = np.concatenate(candidates, axis=1)\n",
    "        return candidates\n",
    "\n",
    "    s_grid = np.linspace(s_min, s_max, 10)\n",
    "    a_grid = np.linspace(a_min, a_max, 10)\n",
    "    y_grid = np.linspace(y_min, y_max, 10)\n",
    "    train_x = np.array(np.meshgrid(s_grid, a_grid, y_grid)).T.reshape(-1,3)\n",
    "    data_x = get_samples_ct(train_x)\n",
    "    data_y = contact_rate(train_x)\n",
    "    data_y = data_y[:,0][:, None]\n",
    "    # data_y = yita_lb + (yita_ub - yita_lb) * data_y\n",
    "\n",
    "    term_names = ['S', 'S^2', 'A', 'Y'] #\n",
    "    lasso_parameter_fitting(data_x, data_y, 'eta', save_path, case_name, True, term_names)\n",
    "\n",
    "\n",
    "    a_grid = np.linspace(0.5, 1.0, 10) # D + R + F\n",
    "    b_grid = np.linspace(chi_min, chi_max, 10)\n",
    "    term_names = ['S + A + Y', r'$\\chi$']\n",
    "    # c_grid = np.ones_like(a_grid) * chi_max\n",
    "    train_x = np.array(np.meshgrid(a_grid, b_grid)).T.reshape(-1,2)\n",
    "    data_x = get_samples_beta(train_x)\n",
    "    data_y = beta(train_x)\n",
    "    data_y = data_y[:,0][:, None]\n",
    "    lasso_parameter_fitting(data_x[:, :], data_y, 'beta', save_path, case_name, True, term_names)\n",
    "\n",
    "    a_grid = np.linspace(a_min, a_max, 10)\n",
    "    b_grid = np.linspace(y_min, y_max, 10)\n",
    "    term_names = ['A', 'Y']\n",
    "    # c_grid = np.ones_like(a_grid) * chi_max\n",
    "    train_x = np.array(np.meshgrid(a_grid, b_grid)).T.reshape(-1,2)\n",
    "    data_x = get_samples_tau(train_x)\n",
    "    data_y = tau(train_x)\n",
    "    data_y = data_y[:,0][:, None]\n",
    "    # data_y = tau_lb + (tau_ub - tau_lb) * data_y\n",
    "    lasso_parameter_fitting(data_x[:, :], data_y, 'tau', save_path, case_name, True, term_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

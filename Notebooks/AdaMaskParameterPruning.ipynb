{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import joblib\n",
    "from re import finditer\n",
    "\n",
    "from Modules.Utils.Imports import *\n",
    "from Modules.Utils.DRUMSLasso import *\n",
    "from Modules.Utils.GetLowestGPU import *\n",
    "import Modules.Loaders.DataFormatter as DF\n",
    "from Modules.Models.BuildBINNs import AdaMaskBINNCovasim\n",
    "from Modules.Models.BuildBINNs import chi\n",
    "from Modules.Utils.ModelWrapper import ModelWrapper\n",
    "from Modules.Utils.PruneEquation import PruneEquation\n",
    "\n",
    "from Notebooks.utils import get_case_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(GetLowestGPU(pick_from=[0,1,2,3]))\n",
    "# helper functions\n",
    "def to_torch(x):\n",
    "    return torch.from_numpy(x).float().to(device)\n",
    "def to_numpy(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate BINN model parameters and path\n",
    "path = '../Data/covasim_data/drums_data/'\n",
    "\n",
    "population = int(500e3)\n",
    "test_prob = 0.1\n",
    "trace_prob = 0.3\n",
    "keep_d = True\n",
    "retrain = False\n",
    "dynamic = True\n",
    "masking = 1\n",
    "multiple = True\n",
    "parallelb = True\n",
    "n_runs = 64\n",
    "chi_type = 'piecewise'\n",
    "\n",
    "# model parameters\n",
    "maskb = True\n",
    "masking_learned = False\n",
    "\n",
    "case_name = get_case_name(population, test_prob, trace_prob, keep_d, dynamic=dynamic, chi_type=chi_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not masking==0:\n",
    "    if masking==1:\n",
    "        case_name = case_name + '_maskingdem'\n",
    "    elif masking==2:\n",
    "        case_name = case_name + '_maskinguni'\n",
    "    elif masking==3:\n",
    "        case_name = case_name + '_maskingnorm'\n",
    "\n",
    "if multiple:\n",
    "    params = DF.load_covasim_data(path, population, test_prob, trace_prob, keep_d, case_name + '_' + str(n_runs), plot=False)\n",
    "else:\n",
    "    params = DF.load_covasim_data(path, population, test_prob, trace_prob, keep_d, case_name, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiple==True and parallelb==False means that data is a list and not normalized\n",
    "if multiple and not parallelb:\n",
    "    data = np.mean(params['data'], axis=0)\n",
    "    data = (data / params['population'])\n",
    "    avg_masking = np.mean(params['avg_masking'], axis=0)\n",
    "    avg_masking = (avg_masking / params['population'])\n",
    "# multiple==True and parallelb==True means that the data is a 2d array and normalized\n",
    "elif multiple and parallelb:\n",
    "    data = params['data'] # parallel simulations store normalized data\n",
    "    avg_masking = params['avg_masking']\n",
    "# otherwise, the data is from a single simulation and is not normalized\n",
    "else:\n",
    "    data = params['data']\n",
    "    data = (data / params['population']).to_numpy()\n",
    "    avg_masking = params['avg_masking']\n",
    "    avg_masking = (avg_masking / params['population'])\n",
    "    \n",
    "params.pop('data')\n",
    "\n",
    "N = len(data)\n",
    "t_max = N - 1\n",
    "t = np.arange(N)[:,None]\n",
    "\n",
    "tracing_array = params['tracing_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../models/covasim'\n",
    "if maskb:\n",
    "    model_path += '/mask'\n",
    "    if masking_learned:\n",
    "        model_path += '/learned_masking'\n",
    "    else:\n",
    "        model_path += '/observed_masking'\n",
    "else:\n",
    "    model_path += '/no_mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------no masking----------------------#\n",
    "# model_folder = '/2023-07-20_17-53-03' # no masking, 500e3 pop, dynamic piecewise, 64 avg., 800e3 epochs, lr=1e-5\n",
    "# model_folder = '/2023-07-21_18-42-24' # no masking, 500e3 pop, dynamic piecewise, 64 avg., 1e6 epochs, lr=1e-6\n",
    "# model_folder = '/2023-07-22_10-20-01' # no masking, 500e3 pop, dynamic piecewise, 64 avg., 1e6 epochs, lr=5e-6\n",
    "# model_folder = '/2023-07-23_00-48-24' # no masking, 500e3 pop, dynamic piecewise, 64 avg., 1e6 epochs, lr=9e-6\n",
    "# model_folder = '/2023-07-23_15-17-23' # no masking, 500e3 pop, dynamic piecewise, 64 avg., 1e6 epochs, lr=9e-6\n",
    "\n",
    "#------------------normal masking--------------------#\n",
    "# model_folder = '/2023-07-20_18-13-01' # masking-norm, observed M, 500e3, dynamic piecewise, 64 avg., 800e3, lr=5e-5\n",
    "# model_folder = '/2023-07-21_18-41-30' # masking-norm, observed M, 500e3, dynamic piecewise, 64 avg., 800e3, lr=5e-5\n",
    "# model_folder = '/2023-07-21_21-48-16' # masking-norm, observed M, 1e6, dynamic piecewise, 64 avg., 800e3, lr=5e-5\n",
    "# model_folder = '/2023-07-22_10-16-47' # masking-norm, observed M, 1e6, dynamic piecewise, 64 avg., 800e3, lr=5e-5\n",
    "# model_folder = '/2023-07-22_12-30-47' # masking-norm, observed M, 1e6, dynamic piecewise, 64 avg., 800e3, lr=5e-5\n",
    "# model_folder = '/2023-07-23_00-01-28' # masking-norm, observed M, 1e6, dynamic piecewise, 64 avg., 800e3, lr=5e-5\n",
    "# model_folder = '/2023-07-23_00-27-07' # masking-norm, observed M, 1e6, dynamic piecewise, 64 avg., 800e3, lr=5e-5\n",
    "# model_folder = '/2023-07-23_15-14-54' # masking-norm, observed M, 1e6, dynamic piecewise, 64 avg., 800e3, lr=4e-5\n",
    "\n",
    "#---------------demographic masking------------------#\n",
    "# model_folder = '/2023-07-20_22-20-10' # masking-dem, observed M, 500e3, dynamic piecewise, 64 avg., 600e3, lr=5e-5\n",
    "# model_folder = '/2023-07-23_15-15-56' # masking-dem, observed M, 500e3, dynamic piecewise, 64 avg., 600e3, lr=3e-6\n",
    "# model_folder = '/2023-07-24_23-09-21' # masking-dem, observed M, 500e3, dynamic piecewise, 64 avg., 600e3, lr=3e-6\n",
    "# model_folder = '/2023-07-24_23-09-34' # masking-dem, observed M, 500e3, dynamic piecewise, 64 avg., 600e3, lr=3e-6\n",
    "model_folder = '/2023-07-25_20-44-25' # masking-dem, observed M, 500e3, dynamic piecewise, 64 avg., 700e3, lr=4e-6\n",
    "\n",
    "mydir = model_path + model_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "yita_lb = 0.0\n",
    "yita_ub = 1.0\n",
    "beta_lb = 0.0\n",
    "beta_ub = 0.5\n",
    "tau_lb = 0.0\n",
    "tau_ub = 0.5\n",
    "eta_deep = True\n",
    "beta_deep = True\n",
    "tau_deep = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "binn = AdaMaskBINNCovasim(params, \n",
    "                t_max_real=t_max, \n",
    "                tracing_array=tracing_array, \n",
    "                yita_lb=None, \n",
    "                yita_ub=None,\n",
    "                beta_lb=None,\n",
    "                beta_ub=None,\n",
    "                tau_lb=tau_lb,\n",
    "                tau_ub=tau_ub, \n",
    "                chi_type=chi_type,\n",
    "                eta_deep=eta_deep,\n",
    "                beta_deep=beta_deep,\n",
    "                tau_deep=tau_deep,\n",
    "                maskb=maskb,\n",
    "                masking_learned=masking_learned).to(device)\n",
    "parameters = binn.parameters()\n",
    "model = ModelWrapper(binn, None, None, save_name=os.path.join(mydir, case_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model weights\n",
    "# model.save_name = '../Weights/'\n",
    "# model.save_name += case_name\n",
    "if retrain:\n",
    "    model.save_name += '_retrain'\n",
    "model.save_name += '_best_val'\n",
    "model.load(model.save_name + '_model', device=device)\n",
    "save_path = model.save_folder\n",
    "# grab initial condition\n",
    "u0 = data[0, :].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab value ranges\n",
    "yita_lb, yita_ub = model.model.yita_lb, model.model.yita_ub\n",
    "beta_lb, beta_ub = model.model.beta_lb, model.model.beta_ub\n",
    "tau_lb, tau_ub = model.model.tau_lb, model.model.tau_ub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learned contact_rate function\n",
    "def contact_rate(u):\n",
    "    res = binn.eta_func(to_torch(u)) # [:,[0,3,4]]\n",
    "    return to_numpy(res)\n",
    "\n",
    "# learned effective tracing rate function\n",
    "def beta(u):\n",
    "    res = binn.beta_func(to_torch(u))\n",
    "    return to_numpy(res)\n",
    "\n",
    "# learned diagnosis of quarantined rate function\n",
    "def tau(u):\n",
    "    res = binn.tau_func(to_torch(u))\n",
    "    return to_numpy(res)\n",
    "\n",
    "def chi_func(t):\n",
    "    chi_t = chi(1 + to_torch(t) * t_max, trace_prob, chi_type)\n",
    "    return chi_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the values of $\\eta, \\beta, \\tau$ evaluated on the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if masking > 0:\n",
    "    all_data = np.concatenate([data, avg_masking[:,None]], axis=1) # STEAYDQRFM\n",
    "else:\n",
    "    all_data = data\n",
    "\n",
    "if maskb:\n",
    "    eta_input = np.concatenate([data[:,[0,3,4]], avg_masking[:,None]], axis=1) #SAYM\n",
    "else:\n",
    "    eta_input = np.concatenate([data[:,[0,3,4]]], axis=1) #SAY\n",
    "eta0 = contact_rate(eta_input) # eta(S,A,Y,M)\n",
    "eta_values = yita_lb + (yita_ub - yita_lb) * eta0[:, 0][:, None]\n",
    "\n",
    "chi_t = to_numpy(chi_func(t))\n",
    "beta_input = np.concatenate([np.sum(data[:,[0,3,4]], axis=1)[:,None], chi_t], axis=1)\n",
    "beta_values = beta(beta_input)\n",
    "\n",
    "tau_input = data[:,[3,4]]\n",
    "tau0 = tau(tau_input)\n",
    "tau_values = tau_lb + (tau_ub - tau_lb) * tau0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the results of LASSO on $\\eta, \\beta, \\tau$ for a desired number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_dl = joblib.load(mydir + '/' + case_name + '/eta_eq_coef/' + case_name + '_' + str(n_runs) + '_sparse_coef_11comps')\n",
    "beta_dl = joblib.load(mydir + '/' + case_name + '/beta_eq_coef/' + case_name + '_' + str(n_runs) + '_sparse_coef_4comps')\n",
    "tau_dl = joblib.load(mydir + '/' + case_name + '/tau_eq_coef/' + case_name + '_' + str(n_runs) + '_sparse_coef_1comps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_lasso = eta_dl['Lasso']\n",
    "beta_lasso = beta_dl['Lasso']\n",
    "tau_lasso = tau_dl['Lasso']\n",
    "\n",
    "eta_eq = eta_dl['Equation']\n",
    "beta_eq = beta_dl['Equation']\n",
    "tau_eq = tau_dl['Equation']\n",
    "\n",
    "eta_coef = np.append(eta_lasso.intercept_, eta_lasso.coef_)\n",
    "beta_coef = np.append(beta_lasso.intercept_, beta_lasso.coef_)\n",
    "tau_coef = np.append(tau_lasso.intercept_, tau_lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_reg_coef = eta_coef[eta_coef.nonzero()]\n",
    "beta_reg_coef = beta_coef[beta_coef.nonzero()]\n",
    "tau_reg_coef = tau_coef[tau_coef.nonzero()]\n",
    "#tau_reg_coef = np.where(np.abs(tau_coef) < float(1e-6), 0, tau_coef)\n",
    "#tau_reg_coef = tau_reg_coef[tau_reg_coef.nonzero()]\n",
    "\n",
    "eta_rhs = eta_eq[4:]\n",
    "beta_rhs = beta_eq[4:]\n",
    "tau_rhs = tau_eq[4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the feature names from the equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_features = []\n",
    "eta_rhs_split = eta_rhs.split('*')\n",
    "for i, elem in enumerate(eta_rhs_split):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    else:\n",
    "        sl = elem.split(' +')\n",
    "        eta_features.append(sl[0])\n",
    "        \n",
    "beta_features = []\n",
    "beta_rhs_split = beta_rhs.split('*')\n",
    "for i, elem in enumerate(beta_rhs_split):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    else:\n",
    "        sl = elem.split(' +')\n",
    "        beta_features.append(sl[0])\n",
    "        \n",
    "tau_features = []\n",
    "tau_rhs_split = tau_rhs.split('*')\n",
    "for i, elem in enumerate(tau_rhs_split):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    else:\n",
    "        sl = elem.split(' +')\n",
    "        tau_features.append(sl[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform the data to be up to degreee 2 and initialize dictionary to store information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "if maskb:\n",
    "    all_data = np.concatenate((data, avg_masking[:,None]), axis=1)\n",
    "else:\n",
    "    all_data = data\n",
    "X = poly.fit_transform(all_data)\n",
    "\n",
    "eta_theta0 = X[:,eta_coef.nonzero()[0]]\n",
    "beta_theta0 = X[:,beta_coef.nonzero()[0]]\n",
    "tau_theta0 = X[:,tau_coef.nonzero()[0]]\n",
    "\n",
    "eta_theta_od = dict()\n",
    "beta_theta_od = dict()\n",
    "tau_theta_od = dict()\n",
    "\n",
    "eta_theta_od['features'] = eta_features\n",
    "eta_theta_od['theta'] = eta_theta0\n",
    "\n",
    "beta_theta_od['features'] = beta_features\n",
    "beta_theta_od['theta'] = beta_theta0\n",
    "\n",
    "tau_theta_od['features'] = tau_features\n",
    "tau_theta_od['theta'] = tau_theta0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the pruning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_theta_nd = PruneEquation(eta_theta_od, eta_values, alpha=0.1, max_pruning=5)\n",
    "#beta_theta_nd = PruneEquation(beta_theta_od, beta_values, alpha=0.1, max_pruning=5)\n",
    "#tau_theta_nd = PruneEquation(tau_theta_od, tau_values, alpha=0.1, max_pruning=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original components of eta are: ['S', 'A', 'Y', 'M', 'S^2', 'S A', 'S Y', 'S M', 'A M', 'Y M', 'M^2']\n",
      "\n",
      "The components of eta after pruning are: ['S Y', 'S M', 'A M', 'Y M', 'M^2']\n"
     ]
    }
   ],
   "source": [
    "print(f\"The original components of eta are: {eta_theta_nd['old_features']}\")\n",
    "print()\n",
    "print(f\"The components of eta after pruning are: {eta_theta_nd['features']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['R',\n",
       " 'M',\n",
       " 'S^2',\n",
       " 'S T',\n",
       " 'S E',\n",
       " 'S A',\n",
       " 'S Y',\n",
       " 'S D',\n",
       " 'S R',\n",
       " 'S M',\n",
       " 'E M',\n",
       " 'R^2',\n",
       " 'R M',\n",
       " 'M^2']"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array_equal(eta_theta_nd['old_features'], eta_theta_nd['features']))\n",
    "eta_theta_nd['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['S E', 'S A', 'S Y', 'S R', 'T R']"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_theta_od['features'] = beta_features\n",
    "beta_theta_od['theta'] = beta_theta0\n",
    "\n",
    "beta_theta_nd = PruneEquation(beta_theta_od, beta_values, alpha=0.1, max_pruning=5)\n",
    "\n",
    "print(np.array_equal(beta_theta_nd['old_features'], beta_theta_nd['features']))\n",
    "beta_theta_nd['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[442], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m tau_theta_od[\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tau_features\n\u001b[0;32m      2\u001b[0m tau_theta_od[\u001b[39m'\u001b[39m\u001b[39mtheta\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m tau_theta0\n\u001b[1;32m----> 4\u001b[0m tau_theta_nd \u001b[39m=\u001b[39m PruneEquation(tau_theta_od, tau_values, alpha\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, max_pruning\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[0;32m      6\u001b[0m \u001b[39mprint\u001b[39m(np\u001b[39m.\u001b[39marray_equal(tau_theta_nd[\u001b[39m'\u001b[39m\u001b[39mold_features\u001b[39m\u001b[39m'\u001b[39m], tau_theta_nd[\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[0;32m      7\u001b[0m tau_theta_nd[\u001b[39m'\u001b[39m\u001b[39mfeatures\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\Documents\\UG Research\\DRUMS\\COVASIM_EQL_BINNS\\Notebooks\\..\\Modules\\Utils\\PruneEquation.py:63\u001b[0m, in \u001b[0;36mPruneEquation\u001b[1;34m(theta_old_dict, y, alpha, max_pruning)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mif\u001b[39;00m max_pruning \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:   max_pruning \u001b[39m=\u001b[39m theta_0\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m     62\u001b[0m \u001b[39mwhile\u001b[39;00m pruned \u001b[39mand\u001b[39;00m num_pruned \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m max_pruning:\n\u001b[1;32m---> 63\u001b[0m     pruned, theta_curr, val_curr, pruned_features \u001b[39m=\u001b[39m prune(lm, theta_curr, y, val0, curr_feature_arr, pruned_features, alpha)\n\u001b[0;32m     64\u001b[0m     \u001b[39mfor\u001b[39;00m elem \u001b[39min\u001b[39;00m curr_feature_arr:\n\u001b[0;32m     65\u001b[0m         \u001b[39mif\u001b[39;00m elem \u001b[39min\u001b[39;00m pruned_features:\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "tau_theta_od['features'] = tau_features\n",
    "tau_theta_od['theta'] = tau_theta0\n",
    "\n",
    "tau_theta_nd = PruneEquation(tau_theta_od, tau_values, alpha=0.1, max_pruning=5)\n",
    "\n",
    "print(np.array_equal(tau_theta_nd['old_features'], tau_theta_nd['features']))\n",
    "tau_theta_nd['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Teddy\\anaconda3\\envs\\reu_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "import joblib\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from Modules.Utils.Imports import *\n",
    "from Modules.Utils.ModelWrapper import ModelWrapper\n",
    "from Modules.Models.BuildBINNs import BINNCovasim_DRUMS\n",
    "\n",
    "import Modules.Loaders.DataFormatter as DF\n",
    "import datetime\n",
    "\n",
    "from utils import plot_loss_convergence, get_case_name\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(GetLowestGPU(pick_from=[0,1,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Data/covasim_data/drums_data/'\n",
    "population = 200000\n",
    "test_prob = 0.1\n",
    "trace_prob = 0.3\n",
    "keep_d = True\n",
    "retrain = False\n",
    "dynamic=True\n",
    "chi_type = 'piecewise'\n",
    "case_name = get_case_name(population, test_prob, trace_prob, keep_d, dynamic=dynamic, chi_type=chi_type)\n",
    "\n",
    "params = DF.load_covasim_data(path, population, test_prob, trace_prob, keep_d, case_name,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_torch(ndarray):\n",
    "    arr = torch.tensor(ndarray, dtype=torch.float)\n",
    "    arr.requires_grad_(True)\n",
    "    arr = arr.to(device)\n",
    "    return arr\n",
    "\n",
    "def to_numpy(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/val and convert to torch\n",
    "data = params['data']\n",
    "data = (data / params['population']).to_numpy()\n",
    "params.pop('data')\n",
    "N = len(data)\n",
    "split = int(0.8*N)\n",
    "p = np.random.permutation(N)\n",
    "x_train = to_torch(p[:split][:, None]/(N-1))\n",
    "y_train = to_torch(data[p[:split]])\n",
    "x_val = to_torch(p[split:][:, None]/(N-1))\n",
    "y_val = to_torch(data[p[split:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate save path\n",
    "mydir = os.path.join('../models/covasim', datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "os.makedirs(mydir)\n",
    "\n",
    "tracing_array = params['tracing_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BINNCovasim_DRUMS(\n",
       "  (surface_fitter): main_MLP(\n",
       "    (mlp): BuildMLP(\n",
       "      (activation): ReLU()\n",
       "      (output_activation): ReLU()\n",
       "      (MLP): Sequential(\n",
       "        (0): Linear(in_features=1, out_features=512, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Dropout(p=0.2, inplace=False)\n",
       "        (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (7): ReLU()\n",
       "        (8): Dropout(p=0.2, inplace=False)\n",
       "        (9): Linear(in_features=256, out_features=9, bias=True)\n",
       "        (10): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (softmax): Softmax(dim=1)\n",
       "  )\n",
       "  (eta_func): infect_rate_MLP(\n",
       "    (mlp): BuildMLP(\n",
       "      (activation): ReLU()\n",
       "      (output_activation): Sigmoid()\n",
       "      (MLP): Sequential(\n",
       "        (0): Linear(in_features=3, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (beta_func): beta_MLP(\n",
       "    (mlp): BuildMLP(\n",
       "      (activation): ReLU()\n",
       "      (output_activation): Sigmoid()\n",
       "      (MLP): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tau_func): tau_MLP(\n",
       "    (mlp): BuildMLP(\n",
       "      (activation): ReLU()\n",
       "      (output_activation): Sigmoid()\n",
       "      (MLP): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mu_func): mu_MLP(\n",
       "    (mlp): BuildMLP(\n",
       "      (activation): ReLU()\n",
       "      (output_activation): Sigmoid()\n",
       "      (MLP): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model\n",
    "binn = BINNCovasim_DRUMS(params, N - 1, tracing_array, keep_d=keep_d, chi_type=chi_type)\n",
    "binn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "parameters = binn.parameters()\n",
    "opt = torch.optim.Adam(parameters, lr=1e-3)\n",
    "os.makedirs(os.path.join(mydir, case_name))\n",
    "model = ModelWrapper(\n",
    "    model=binn,\n",
    "    optimizer=opt,\n",
    "    loss=binn.loss,\n",
    "    augmentation=None,\n",
    "    # scheduler= scheduler,\n",
    "    save_name=os.path.join(mydir, case_name) )\n",
    "model.str_name = 'STEAYDQRF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the range information before training\n",
    "ranges = [binn.yita_lb, binn.yita_ub, binn.beta_lb, binn.beta_ub, binn.tau_lb, binn.tau_ub, binn.mu_lb, binn.mu_ub]\n",
    "file_name = '_'.join([str(m) for m in ranges])\n",
    "joblib.dump(None, os.path.join(mydir, file_name)) # model.save_folder\n",
    "# if retrain\n",
    "if retrain:\n",
    "    model.load(model.save_name + '_best_val_model', device=device)\n",
    "    model.model.train()\n",
    "    model.save_name += '_retrain'\n",
    "epochs = int(2000)\n",
    "batch_size = 128\n",
    "rel_save_thresh = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 153 | Train loss = 2.6118e+00 | Val loss = 1.1325e+00 | Remaining = 3:35:02           "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# train jointly\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m      3\u001b[0m     x\u001b[39m=\u001b[39;49mx_train,\n\u001b[0;32m      4\u001b[0m     y\u001b[39m=\u001b[39;49my_train,\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m      6\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[0;32m      7\u001b[0m     callbacks\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m      8\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m      9\u001b[0m     validation_data\u001b[39m=\u001b[39;49m[x_val, y_val],\n\u001b[0;32m     10\u001b[0m     early_stopping\u001b[39m=\u001b[39;49m\u001b[39m40000\u001b[39;49m,\n\u001b[0;32m     11\u001b[0m     rel_save_thresh\u001b[39m=\u001b[39;49mrel_save_thresh)\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\Documents\\UG Research\\DRUMS\\COVASIM_EQL_BINNS\\Notebooks\\..\\Modules\\Utils\\ModelWrapper.py:373\u001b[0m, in \u001b[0;36mModelWrapper.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, early_stopping, best_train_loss, best_val_loss, include_val_aug, include_val_reg, lr_dec_epoch, lr_dec_prop, rel_save_thresh)\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mplot(x_true, y_true, y_pred, epoch, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    372\u001b[0m \u001b[39m# compute loss \u001b[39;00m\n\u001b[1;32m--> 373\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloss(y_pred, y_true)\n\u001b[0;32m    375\u001b[0m \u001b[39m# optionally include regularization in val loss\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[39mif\u001b[39;00m include_val_reg \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mregularizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\Documents\\UG Research\\DRUMS\\COVASIM_EQL_BINNS\\Notebooks\\..\\Modules\\Models\\BuildBINNs.py:554\u001b[0m, in \u001b[0;36mBINNCovasim_DRUMS.loss\u001b[1;34m(self, pred, true)\u001b[0m\n\u001b[0;32m    552\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpde_weight \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    553\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeep_d:\n\u001b[1;32m--> 554\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpde_loss_val \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpde_weight \u001b[39m*\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpde_loss(inputs_rand, outputs_rand)\n\u001b[0;32m    555\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    556\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpde_loss_val \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpde_weight \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpde_loss_no_d(inputs_rand, outputs_rand)\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\Documents\\UG Research\\DRUMS\\COVASIM_EQL_BINNS\\Notebooks\\..\\Modules\\Models\\BuildBINNs.py:398\u001b[0m, in \u001b[0;36mBINNCovasim_DRUMS.pde_loss\u001b[1;34m(self, inputs, outputs, return_mean)\u001b[0m\n\u001b[0;32m    396\u001b[0m new_d \u001b[39m=\u001b[39m mu \u001b[39m*\u001b[39m y \u001b[39m+\u001b[39m tau \u001b[39m*\u001b[39m q\n\u001b[0;32m    397\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_com):\n\u001b[1;32m--> 398\u001b[0m     d1 \u001b[39m=\u001b[39m Gradient(u[:, i], inputs, order\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    399\u001b[0m     ut \u001b[39m=\u001b[39m d1[:, \u001b[39m0\u001b[39m][:, \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m    400\u001b[0m     LHS \u001b[39m=\u001b[39m ut \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mt_max_real\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\Documents\\UG Research\\DRUMS\\COVASIM_EQL_BINNS\\Notebooks\\..\\Modules\\Utils\\Gradient.py:25\u001b[0m, in \u001b[0;36mGradient\u001b[1;34m(outputs, inputs, order)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m# compute gradients sequentially until order is reached\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(order):\n\u001b[1;32m---> 25\u001b[0m     grads \u001b[39m=\u001b[39m grad(outputs, inputs, create_graph\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m0\u001b[39m]\n\u001b[0;32m     26\u001b[0m     outputs \u001b[39m=\u001b[39m grads\u001b[39m.\u001b[39msum()\n\u001b[0;32m     28\u001b[0m \u001b[39mreturn\u001b[39;00m grads\n",
      "File \u001b[1;32mc:\\Users\\Teddy\\anaconda3\\envs\\reu_env\\lib\\site-packages\\torch\\autograd\\__init__.py:276\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \u001b[39mreturn\u001b[39;00m _vmap_internals\u001b[39m.\u001b[39m_vmap(vjp, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, allow_none_pass_through\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[0;32m    275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 276\u001b[0m     \u001b[39mreturn\u001b[39;00m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    277\u001b[0m         t_outputs, grad_outputs_, retain_graph, create_graph, t_inputs,\n\u001b[0;32m    278\u001b[0m         allow_unused, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train jointly\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=None,\n",
    "    verbose=1,\n",
    "    validation_data=[x_val, y_val],\n",
    "    early_stopping=40000,\n",
    "    rel_save_thresh=rel_save_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting performance on training data\n",
    "y_train_pred = to_numpy(model.predict(x_train))\n",
    "\n",
    "\n",
    "# load training errors\n",
    "total_train_losses = model.train_loss_list\n",
    "total_val_losses = model.val_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_convergence(total_train_losses, total_val_losses, rel_save_thresh, model.save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.save_name)\n",
    "\n",
    "u = binn.surface_fitter(x_val)\n",
    "u_arr = u.detach().numpy()\n",
    "u_mean = np.mean(u_arr, axis=0)\n",
    "# print average values for each solution/compartment\n",
    "print(u_mean)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

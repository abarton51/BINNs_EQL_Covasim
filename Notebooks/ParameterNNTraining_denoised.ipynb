{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter MLPs\n",
    "This notebook uses the `NNComponentsCV` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import sys\n",
    "import joblib\n",
    "import datetime\n",
    "sys.path.append('../')\n",
    "\n",
    "from Modules.Utils.ModelWrapper import ModelWrapper\n",
    "from Modules.Models.BuildBINNs import NNComponentsCV\n",
    "from Modules.Utils.Imports import *\n",
    "\n",
    "import Modules.Loaders.DataFormatter as DF\n",
    "from utils import plot_loss_convergence, get_case_name\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(GetLowestGPU(pick_from=[0,1,2,3]))\n",
    "# helper functions\n",
    "def to_torch(ndarray):\n",
    "    arr = torch.tensor(ndarray, dtype=torch.float)\n",
    "    arr.requires_grad_(True)\n",
    "    arr = arr.to(device)\n",
    "    return arr\n",
    "\n",
    "def to_numpy(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate BINN model parameters and path\n",
    "path = '../Data/covasim_data/drums_data/'\n",
    "population = int(200e3) # 200000, 100000\n",
    "test_prob = 0.1\n",
    "trace_prob = 0.3\n",
    "keep_d = True\n",
    "retrain = False\n",
    "dynamic = True\n",
    "masking = 3\n",
    "parallelb = True\n",
    "n_runs = 1024\n",
    "chi_type = 'piecewise'\n",
    "\n",
    "plot = False\n",
    "trim = False\n",
    "\n",
    "case_name = get_case_name(population, test_prob, trace_prob, keep_d, dynamic=dynamic, chi_type=chi_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not masking==0:\n",
    "    if masking==1:\n",
    "        case_name = case_name + '_maskingthresh'\n",
    "    elif masking==2:\n",
    "        case_name = case_name + '_maskinguni'\n",
    "    elif masking==3:\n",
    "        case_name = case_name + '_maskingnorm'\n",
    "    \n",
    "params = DF.load_covasim_data(path, population, test_prob, trace_prob, keep_d, case_name + '_' + str(n_runs), plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parallelb:\n",
    "    data_smooth = params['data']\n",
    "else:\n",
    "    data_smooth = params['data']\n",
    "    data_smooth = np.mean(data_smooth, axis=1)\n",
    "    data_smooth = (data_smooth / params['population'])\n",
    "    \n",
    "if trim:\n",
    "    N = len(data_smooth) - 17\n",
    "    u = to_torch(data_smooth[16:N+16,:])\n",
    "else:\n",
    "    N = len(data_smooth) - 2\n",
    "    u = to_torch(data_smooth[1:N+1,:])\n",
    "\n",
    "t_max_real = N + 1\n",
    "t = np.arange(N)[:,None] + 1\n",
    "params.pop('data')\n",
    "\n",
    "if masking>0:\n",
    "    avg_masking = params['avg_masking']\n",
    "tracing_array = params['tracing_array']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dmethod = 'savgol' # 'savgol', 'cfd'\n",
    "# central differences numerical differentiation\n",
    "if dmethod=='cfd':\n",
    "    if trim:\n",
    "        u_front = data_smooth[:N+15,:]\n",
    "        u_back = data_smooth[2:,:]\n",
    "    else:\n",
    "        u_front = data_smooth[:N,:]\n",
    "        u_back = data_smooth[2:,:]\n",
    "        \n",
    "    ut = to_torch((u_back - u_front) / 2.)\n",
    "    \n",
    "elif dmethod=='savgol':\n",
    "    ut = to_torch(savgol_filter(data_smooth, 9, 3, deriv=1, axis=0))[1:N+1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train/val and convert to torch\n",
    "split = int(0.8*N)\n",
    "# generate shuffled array of indices from 0 to N-1\n",
    "p = np.random.permutation(N)[:,None]\n",
    "\n",
    "if trim:\n",
    "    u_tensor = torch.cat([u[:,:,None], ut[15:,:,None]], axis=2)\n",
    "else:\n",
    "    u_tensor = torch.cat([u[:,:,None], ut[:,:,None]], axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mars/venv3/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# assign x_train to be randomly shuffled days from 1 to N of size int(0.8 * N)\n",
    "x_train = to_torch((p[:split] + 1)) / t_max_real\n",
    "# assign y_train to be values corresponding to x_train of size int(0.8 * N)\n",
    "y_train = to_torch(u[(p[:split]).flatten()])\n",
    "# assign x_val to be randomly shuffled days from 1 to N of size int(0.2 * N)\n",
    "x_val = to_torch((p[split:] + 1)) / t_max_real\n",
    "# assign y_val to be values corresponding to y_val of size int(0.2 * N)\n",
    "y_val = to_torch(u[(p[split:]).flatten()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn')\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "\n",
    "if plot:\n",
    "    start_idx = 0\n",
    "    if trim:\n",
    "        start_idx = 15\n",
    "    dSdt = ut[start_idx:,0].detach()\n",
    "    dTdt = ut[start_idx:,1].detach()\n",
    "    dEdt = ut[start_idx:,2].detach()\n",
    "    dAdt = ut[start_idx:,3].detach()\n",
    "    dYdt = ut[start_idx:,4].detach()\n",
    "    dDdt = ut[start_idx:,5].detach()\n",
    "    dQdt = ut[start_idx:,6].detach()\n",
    "    dRdt = ut[start_idx:,7].detach()\n",
    "    dFdt = ut[start_idx:,8].detach()\n",
    "    for i in range(9):\n",
    "        if i==0:\n",
    "            plt.title('$dSdt$ versus time (days)')\n",
    "            plt.plot(t, dSdt*population, label='dSdt', color='b')\n",
    "            plt.xlabel('Time (days)')\n",
    "            plt.ylabel('$dSdt$')\n",
    "            plt.legend()\n",
    "            # plt.savefig('../Notebooks/figs/drums/derivatives/' + case_name + '_' + str(n_runs) + '_dSdt' + '.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        if i==1:\n",
    "            plt.title('$dTdt$ versus time (days)')\n",
    "            plt.plot(t, dTdt*population, label='dTdt', color='b')\n",
    "            plt.xlabel('Time (days)')\n",
    "            plt.ylabel('$dTdt$')\n",
    "            plt.legend()\n",
    "            # plt.savefig('../Notebooks/figs/drums/derivatives/' + case_name + '_' + str(n_runs) + '_dTdt' + '.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        if i==2:\n",
    "            plt.title('$dEdt$ versus time (days)')\n",
    "            plt.plot(t, dEdt*population, label='dEdt', color='y')\n",
    "            plt.xlabel('Time (days)')\n",
    "            plt.ylabel('$dEdt$')\n",
    "            plt.legend()\n",
    "            # plt.savefig('../Notebooks/figs/drums/derivatives/' + case_name + '_' + str(n_runs) + '_dEdt' + '.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        if i==3:\n",
    "            plt.title('$dAdt$ versus time (days)')\n",
    "            plt.plot(t, dAdt*population, label='dAdt', color='r')\n",
    "            plt.xlabel('Time (days)')\n",
    "            plt.ylabel('$dAdt$')\n",
    "            plt.legend()\n",
    "            # plt.savefig('../Notebooks/figs/drums/derivatives/' + case_name + '_' + str(n_runs) + '_dAdt' + '.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        if i==4:\n",
    "            plt.title('$dYdt$ versus time (days)')\n",
    "            plt.plot(t, dYdt*population, label='dYdt', color='r')\n",
    "            plt.xlabel('Time (days)')\n",
    "            plt.ylabel('$dYdt$')\n",
    "            plt.legend()\n",
    "            # plt.savefig('../Notebooks/figs/drums/derivatives/' + case_name + '_' + str(n_runs) + '_dYdt' + '.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        if i==5:\n",
    "            plt.title('$dDdt$ versus time (days)')\n",
    "            plt.plot(t, dDdt*population, label='dDdt', color='m')\n",
    "            plt.xlabel('Time (days)')\n",
    "            plt.ylabel('$dDdt$')\n",
    "            plt.legend()\n",
    "            # plt.savefig('../Notebooks/figs/drums/derivatives/' + case_name + '_' + str(n_runs) + '_dDdt' + '.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        if i==6:\n",
    "            plt.title('$dQdt$ versus time (days)')\n",
    "            plt.plot(t, dQdt*population, label='dQdt', color='m')\n",
    "            plt.xlabel('Time (days)')\n",
    "            plt.ylabel('$dQdt$')\n",
    "            plt.legend()\n",
    "            # plt.savefig('../Notebooks/figs/drums/derivatives/' + case_name + '_' + str(n_runs) + '_dQdt' + '.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        if i==7:\n",
    "            plt.title('$dRdt$ versus time (days)')\n",
    "            plt.plot(t, dRdt*population, label='dRdt', color='g')\n",
    "            plt.xlabel('Time (days)')\n",
    "            plt.ylabel('$dRdt$')\n",
    "            plt.legend()\n",
    "            # plt.savefig('../Notebooks/figs/drums/derivatives/' + case_name + '_' + str(n_runs) + '_dRdt' + '.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "        if i==8:\n",
    "            plt.title('$dFdt$ versus time (days)')\n",
    "            plt.plot(t, dFdt*population, label='dFdt', color='k')\n",
    "            plt.xlabel('Time (days)')\n",
    "            plt.ylabel('$dFdt$')\n",
    "            plt.legend()\n",
    "            # plt.savefig('../Notebooks/figs/drums/derivatives/' + case_name + '_' + str(n_runs) + '_dFdt' + '.png')\n",
    "            plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate save path\n",
    "mydir = os.path.join('../models/covasim/denoised', datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "os.makedirs(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model hyperparameters and architecture type\n",
    "mask_input = True\n",
    "eta_deep = True\n",
    "beta_deep = True\n",
    "tau_deep = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNComponentsCV(\n",
       "  (eta_func): eta_NN(\n",
       "    (mlp): BuildMLP(\n",
       "      (activation): ReLU()\n",
       "      (output_activation): Sigmoid()\n",
       "      (MLP): Sequential(\n",
       "        (0): Linear(in_features=4, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Dropout(p=0.2, inplace=False)\n",
       "        (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (7): ReLU()\n",
       "        (8): Dropout(p=0.2, inplace=False)\n",
       "        (9): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (10): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (beta_func): beta_NN(\n",
       "    (mlp): BuildMLP(\n",
       "      (activation): ReLU()\n",
       "      (output_activation): Sigmoid()\n",
       "      (MLP): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (4): ReLU()\n",
       "        (5): Dropout(p=0.2, inplace=False)\n",
       "        (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (7): ReLU()\n",
       "        (8): Dropout(p=0.2, inplace=False)\n",
       "        (9): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (10): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tau_func): tau_NN(\n",
       "    (mlp): BuildMLP(\n",
       "      (activation): ReLU()\n",
       "      (output_activation): Sigmoid()\n",
       "      (MLP): Sequential(\n",
       "        (0): Linear(in_features=2, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Dropout(p=0.2, inplace=False)\n",
       "        (3): Linear(in_features=256, out_features=1, bias=True)\n",
       "        (4): Sigmoid()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize model\n",
    "binn = NNComponentsCV(params, \n",
    "                    u_tensor, \n",
    "                    t_max_real, \n",
    "                    tracing_array,\n",
    "                    keep_d=keep_d, \n",
    "                    chi_type=chi_type,\n",
    "                    mask_input=mask_input,\n",
    "                    eta_deep=eta_deep,\n",
    "                    beta_deep=beta_deep,\n",
    "                    tau_deep=tau_deep)\n",
    "binn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = binn.parameters()\n",
    "opt = torch.optim.Adam(parameters, lr=1e-4)\n",
    "os.makedirs(os.path.join(mydir, case_name))\n",
    "model = ModelWrapper(\n",
    "    model=binn,\n",
    "    optimizer=opt,\n",
    "    loss=binn.loss,\n",
    "    augmentation=None,\n",
    "    # scheduler= scheduler,\n",
    "    save_name=os.path.join(mydir, case_name) )\n",
    "model.str_name = 'STEAYDQRF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the range information before training\n",
    "ranges = [binn.yita_lb, binn.yita_ub, binn.beta_lb, binn.beta_ub, binn.tau_lb, binn.tau_ub]\n",
    "file_name = '_'.join([str(m) for m in ranges])\n",
    "joblib.dump(None, os.path.join(mydir, file_name)) # model.save_folder\n",
    "# if retrain\n",
    "if retrain:\n",
    "    model.load(model.save_name + '_best_val_model', device=device)\n",
    "    model.model.train()\n",
    "    model.save_name += '_retrain'\n",
    "    \n",
    "epochs = int(1000e3)\n",
    "batch_size = 256\n",
    "rel_save_thresh = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14134 | Train loss = 1.2234e-01 | Val loss = 1.1527e-01 | Remaining = 6:50:47                 "
     ]
    }
   ],
   "source": [
    "# train jointly\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=None,\n",
    "    verbose=1,\n",
    "    validation_data=[x_val, y_val],\n",
    "    early_stopping=int(200e3),\n",
    "    rel_save_thresh=rel_save_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_train_losses = model.train_loss_list\n",
    "total_val_losses = model.val_loss_list\n",
    "\n",
    "plot_loss_convergence(total_train_losses, total_val_losses, rel_save_thresh, model.save_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
